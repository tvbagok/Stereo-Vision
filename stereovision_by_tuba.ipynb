{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "#by Tuba GÃ¶k\nimport cv2\nimport numpy as np\nimport os\n\n# Initialize the cameras\ncap_left = cv2.VideoCapture(0)\ncap_right = cv2.VideoCapture(1)\n\n# Create folders to save captured images\nleft_folder = 'left_images'\nright_folder = 'right_images'\nos.makedirs(left_folder, exist_ok=True)\nos.makedirs(right_folder, exist_ok=True)\n\ndef capture_images():\n    ret_left, frame_left = cap_left.read()\n    ret_right, frame_right = cap_right.read()\n    if ret_left and ret_right:\n        return frame_left, frame_right\n    else:\n        return None, None\n\nimage_count = 0\n\nprint(\"Press 's' to save the frame, 'c' to skip, and 'q' to quit.\")\n\nwhile True:\n    frame_left, frame_right = capture_images()\n    if frame_left is not None and frame_right is not None:\n        cv2.imshow('Left Camera', frame_left)\n        cv2.imshow('Right Camera', frame_right)\n\n        key = cv2.waitKey(1) & 0xFF\n        if key == ord('s'):\n            cv2.imwrite(os.path.join(left_folder,\nf'left_{image_count}.png'), frame_left)\n            cv2.imwrite(os.path.join(right_folder,\nf'right_{image_count}.png'), frame_right)\n            print(f\"Saved frame {image_count}\")\n            image_count += 1\n        elif key == ord('c'):\n            print(\"Frame skipped\")\n        elif key == ord('q'):\n            break\n    else:\n        print(\"Failed to capture images from both cameras\")\n\n# Release the cameras and close windows\ncap_left.release()\ncap_right.release()\ncv2.destroyAllWindows()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# Calibration\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\nobjp = np.zeros((8*6, 3), np.float32)\nobjp[:, :2] = np.mgrid[0:8, 0:6].T.reshape(-1, 2) * 25  # 25mm square size\nobjpoints = []\nimgpoints_left = []\nimgpoints_right = []\n\nleft_images = sorted([os.path.join(left_folder, f) for f in\nos.listdir(left_folder) if f.endswith('.png')])\nright_images = sorted([os.path.join(right_folder, f) for f in\nos.listdir(right_folder) if f.endswith('.png')])\n\nfor left_img_path, right_img_path in zip(left_images, right_images):\n    img_left = cv2.imread(left_img_path)\n    img_right = cv2.imread(right_img_path)\n\n    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n\n    ret_left, corners_left = cv2.findChessboardCorners(gray_left, (8, 6), None)\n    ret_right, corners_right = cv2.findChessboardCorners(gray_right,\n(8, 6), None)\n\n    if ret_left and ret_right:\n        objpoints.append(objp)\n\n        corners_left = cv2.cornerSubPix(gray_left, corners_left, (11,\n11), (-1, -1), criteria)\n        imgpoints_left.append(corners_left)\n\n        corners_right = cv2.cornerSubPix(gray_right, corners_right,\n(11, 11), (-1, -1), criteria)\n        imgpoints_right.append(corners_right)\n\n        cv2.drawChessboardCorners(img_left, (8, 6), corners_left, ret_left)\n        cv2.drawChessboardCorners(img_right, (8, 6), corners_right, ret_right)\n        cv2.imshow('img_left', img_left)\n        cv2.imshow('img_right', img_right)\n        cv2.waitKey(500)\n\ncv2.destroyAllWindows()\n\nret_left, mtx_left, dist_left, rvecs_left, tvecs_left =\ncv2.calibrateCamera(objpoints, imgpoints_left, gray_left.shape[::-1],\nNone, None)\nret_right, mtx_right, dist_right, rvecs_right, tvecs_right =\ncv2.calibrateCamera(objpoints, imgpoints_right,\ngray_right.shape[::-1], None, None)\n\nret, mtx_left, dist_left, mtx_right, dist_right, R, T, E, F =\ncv2.stereoCalibrate(\n    objpoints, imgpoints_left, imgpoints_right,\n    mtx_left, dist_left, mtx_right, dist_right,\n    gray_left.shape[::-1], criteria, flags=cv2.CALIB_FIX_INTRINSIC\n)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#rectification\n\n\nR1, R2, P1, P2, Q, roi1, roi2 = cv2.stereoRectify(\n    mtx_left, dist_left, mtx_right, dist_right, gray_left.shape[::-1],\nR, T, alpha=0\n)\n\nmap_left_x, map_left_y = cv2.initUndistortRectifyMap(mtx_left,\ndist_left, R1, P1, gray_left.shape[::-1], cv2.CV_16SC2)\nmap_right_x, map_right_y = cv2.initUndistortRectifyMap(mtx_right,\ndist_right, R2, P2, gray_right.shape[::-1], cv2.CV_16SC2)\n\nimg_left = cv2.imread(left_images[0])\nimg_right = cv2.imread(right_images[0])\n\nrectified_left = cv2.remap(img_left, map_left_x, map_left_y, cv2.INTER_LINEAR)\nrectified_right = cv2.remap(img_right, map_right_x, map_right_y,\ncv2.INTER_LINEAR)\n\ncv2.imshow('rectified_left', rectified_left)\ncv2.imshow('rectified_right', rectified_right)\ncv2.waitKey(0)\ncv2.destroyAllWindows()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#calculating disparity map\n\ndef compute_disparity_map(img_left, img_right):\n    gray_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n    gray_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n\n    gray_left = cv2.GaussianBlur(gray_left, (5, 5), 0)\n    gray_right = cv2.GaussianBlur(gray_right, (5, 5), 0)\n\n    window_size = 5\n    min_disp = 0\n    num_disp = 16 * 12\n\n    stereo = cv2.StereoSGBM_create(\n        minDisparity=min_disp,\n        numDisparities=num_disp,\n        blockSize=window_size,\n        P1=8 * 3 * window_size ** 2,\n        P2=32 * 3 * window_size ** 2,\n        disp12MaxDiff=1,\n        uniquenessRatio=10,\n        speckleWindowSize=50,\n        speckleRange=2,\n        preFilterCap=63,\n        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n    )\n\n    disparity = stereo.compute(gray_left, gray_right).astype(np.float32) / 16.0\n\n    return disparity, min_disp, num_disp",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "# calculating depth and measuring the distance\n\ndef calculate_depth(disparity, Q):\n    epsilon = 1e-6\n    disparity[disparity <= 0] = epsilon\n\n    depth = cv2.reprojectImageTo3D(disparity, Q)[:, :, 2]\n\n    depth[depth > 10000] = np.nan\n\n    return depth\n\ndef measure_distance(depth, mask=None):\n    if mask is not None:\n        depth = np.where(mask, depth, np.nan)\n\n    finite_depth = depth[np.isfinite(depth)]\n    if finite_depth.size == 0:\n        return np.inf\n    avg_distance = np.mean(finite_depth)\n    return avg_distance\n\ncap_left = cv2.VideoCapture(0)\ncap_right = cv2.VideoCapture(1)\n\nprint(\"Press 'q' to quit\")\n\nret, bg_frame_left = cap_left.read()\nbg_frame_left_gray = cv2.cvtColor(bg_frame_left, cv2.COLOR_BGR2GRAY)\n\nwhile True:\n    ret_left, frame_left = cap_left.read()\n    ret_right, frame_right = cap_right.read()\n\n    if ret_left and ret_right:\n        rectified_left = cv2.remap(frame_left, map_left_x, map_left_y,\ncv2.INTER_LINEAR)\n        rectified_right = cv2.remap(frame_right, map_right_x,\nmap_right_y, cv2.INTER_LINEAR)\n\n        disparity, min_disp, num_disp =\ncompute_disparity_map(rectified_left, rectified_right)\n\n        depth = calculate_depth(disparity, Q)\n\n        rectified_left_gray = cv2.cvtColor(rectified_left, cv2.COLOR_BGR2GRAY)\n        diff_frame = cv2.absdiff(rectified_left_gray, bg_frame_left_gray)\n        _, mask = cv2.threshold(diff_frame, 30, 255, cv2.THRESH_BINARY)\n\n        distance = measure_distance(depth, mask) * (0.087)\n        if np.isfinite(distance):\n            print(f\"Measured distance: {distance:.2f} centimeters\")\n        else:\n            print(\"Distance measurement out of bounds\")\n\n        cv2.imshow('rectified_left', rectified_left)\n        cv2.imshow('rectified_right', rectified_right)\n        cv2.imshow('disparity', (disparity - min_disp) / num_disp)\n        cv2.imshow('mask', mask.astype(np.uint8) * 255)\n\n        if cv2.waitKey(1) & 0xFF == ord('q'):\n            break\n    else:\n        print(\"Failed to capture images from both cameras\")\n\ncap_left.release()\ncap_right.release()\ncv2.destroyAllWindows()\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}